# utils/hybrid_llm_manager_gemini.py
import os
import json
import time
from typing import Dict, Any, Optional
from datetime import datetime, timedelta

class HybridLLMManagerGemini:
    """Gestionnaire LLM hybride : Google Gemini -> Groq/Llama 3"""
    
    def __init__(self):
        self.google_api_key = os.getenv("GOOGLE_API_KEY")
        self.gemini_model = os.getenv("GEMINI_MODEL", "gemini-1.5-flash")
        
        # Configuration Groq
        self.groq_api_key = os.getenv("GROQ_API_KEY", "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")
        self.groq_model = os.getenv("GROQ_MODEL", "llama3-8b-8192")
        
        # Configuration des limites (Gemini a des quotas g√©n√©reux)
        self.token_limit_per_hour = 15000   # Limite tokens/heure
        self.token_limit_per_day = 100000   # Limite tokens/jour
        
        # Tracking des tokens
        self.token_usage_file = "config/token_usage_gemini.json"
        self.load_token_usage()
        
        # √âtat du syst√®me
        self.gemini_available = bool(self.google_api_key)
        self.groq_available = self._check_groq()
        self.current_provider = "gemini" if self.gemini_available else "groq"
        
        print(f"ü§ñ LLM Manager Gemini initialis√©")
        print(f"   üîë Gemini: {'‚úÖ Disponible' if self.gemini_available else '‚ùå Pas de cl√©'}")
        print(f"   ü¶ô Groq/Llama 3: {'‚úÖ Disponible' if self.groq_available else '‚ùå Non disponible'}")
        print(f"   üéØ Provider actuel: {self.current_provider}")
    
    def _check_groq(self) -> bool:
        """V√©rifie la disponibilit√© de Groq"""
        try:
            from groq import Groq
            # Tester la connexion
            client = Groq(api_key=self.groq_api_key)
            return True
        except Exception as e:
            print(f"‚ö†Ô∏è Groq non disponible: {e}")
            return False
    
    def load_token_usage(self):
        """Charge l'utilisation des tokens"""
        try:
            if os.path.exists(self.token_usage_file):
                with open(self.token_usage_file, 'r') as f:
                    self.token_usage = json.load(f)
            else:
                self.token_usage = {
                    "daily": {"date": "", "tokens": 0},
                    "hourly": {"hour": "", "tokens": 0}
                }
        except:
            self.token_usage = {
                "daily": {"date": "", "tokens": 0},
                "hourly": {"hour": "", "tokens": 0}
            }
    
    def save_token_usage(self):
        """Sauvegarde l'utilisation des tokens"""
        try:
            os.makedirs(os.path.dirname(self.token_usage_file), exist_ok=True)
            with open(self.token_usage_file, 'w') as f:
                json.dump(self.token_usage, f, indent=2)
        except:
            pass
    
    def update_token_usage(self, tokens: int):
        """Met √† jour le compteur de tokens"""
        now = datetime.now()
        today = now.strftime("%Y-%m-%d")
        current_hour = now.strftime("%Y-%m-%d-%H")
        
        # Reset daily counter if new day
        if self.token_usage["daily"]["date"] != today:
            self.token_usage["daily"] = {"date": today, "tokens": 0}
        
        # Reset hourly counter if new hour
        if self.token_usage["hourly"]["hour"] != current_hour:
            self.token_usage["hourly"] = {"hour": current_hour, "tokens": 0}
        
        # Add tokens
        self.token_usage["daily"]["tokens"] += tokens
        self.token_usage["hourly"]["tokens"] += tokens
        
        self.save_token_usage()
        
        # Log usage
        print(f"üìä Tokens utilis√©s: +{tokens} (Total jour: {self.token_usage['daily']['tokens']}, Heure: {self.token_usage['hourly']['tokens']})")
    
    def should_use_gemini(self) -> bool:
        """D√©termine si on peut utiliser Gemini"""
        if not self.gemini_available:
            return False
        
        # V√©rifier les limites de tokens
        if self.token_usage["hourly"]["tokens"] >= self.token_limit_per_hour:
            print(f"‚ö†Ô∏è Limite horaire atteinte ({self.token_usage['hourly']['tokens']}/{self.token_limit_per_hour})")
            return False
        
        if self.token_usage["daily"]["tokens"] >= self.token_limit_per_day:
            print(f"‚ö†Ô∏è Limite quotidienne atteinte ({self.token_usage['daily']['tokens']}/{self.token_limit_per_day})")
            return False
        
        return True
    
    def generate_with_gemini(self, prompt: str, system_prompt: str = None) -> str:
        """G√©n√®re avec Google Gemini"""
        try:
            import google.generativeai as genai
            
            # Configuration Gemini
            genai.configure(api_key=self.google_api_key)
            model = genai.GenerativeModel(self.gemini_model)
            
            # Construire le prompt complet
            if system_prompt:
                full_prompt = f"{system_prompt}\n\nQuestion: {prompt}"
            else:
                full_prompt = prompt
            
            print("üîÑ G√©n√©ration avec Google Gemini...")
            
            # Configuration de g√©n√©ration
            generation_config = genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=1024,
                top_p=0.9,
            )
            
            response = model.generate_content(
                full_prompt,
                generation_config=generation_config
            )
            
            if response.text:
                # Estimer les tokens utilis√©s
                estimated_tokens = len(prompt.split()) + len(response.text.split()) + (len(system_prompt.split()) if system_prompt else 0)
                self.update_token_usage(estimated_tokens)
                
                print(f"‚úÖ R√©ponse Gemini g√©n√©r√©e ({len(response.text)} chars)")
                return response.text
            else:
                return "Erreur: R√©ponse vide de Gemini"
            
        except Exception as e:
            error_str = str(e).lower()
            print(f"‚ùå Erreur Gemini: {e}")
            
            # V√©rifier si c'est un probl√®me de quota
            if any(keyword in error_str for keyword in ["quota", "429", "rate limit", "resource_exhausted"]):
                print("üîÑ Quota Gemini √©puis√©, basculement vers Groq/Llama 3")
                self.gemini_available = False
                return self.generate_with_groq(prompt, system_prompt)
            elif any(keyword in error_str for keyword in ["401", "invalid", "unauthorized", "api_key"]):
                print("üîÑ Cl√© Gemini invalide, basculement vers Groq/Llama 3")
                self.gemini_available = False
                return self.generate_with_groq(prompt, system_prompt)
            else:
                print("üîÑ Erreur Gemini, tentative avec Groq/Llama 3")
                return self.generate_with_groq(prompt, system_prompt)
    
    def generate_with_groq(self, prompt: str, system_prompt: str = None) -> str:
        """G√©n√®re avec Groq/Llama 3"""
        try:
            from groq import Groq
            
            # Initialiser le client Groq
            client = Groq(api_key=self.groq_api_key)
            
            # Construire les messages
            messages = []
            
            if system_prompt:
                messages.append({
                    "role": "system",
                    "content": system_prompt
                })
            
            messages.append({
                "role": "user",
                "content": prompt
            })
            
            print("ü¶ô G√©n√©ration avec Groq/Llama 3...")
            
            # Appel √† l'API Groq
            completion = client.chat.completions.create(
                model=self.groq_model,
                messages=messages,
                temperature=0.7,
                max_tokens=1024,
                top_p=0.9,
                stream=False
            )
            
            response_text = completion.choices[0].message.content
            print(f"‚úÖ R√©ponse Groq/Llama 3 g√©n√©r√©e ({len(response_text)} chars)")
            return response_text
                
        except Exception as e:
            print(f"‚ùå Erreur Groq: {e}")
            
            # V√©rifier le type d'erreur
            error_str = str(e).lower()
            if "rate limit" in error_str:
                return "Limite de taux Groq atteinte. Veuillez r√©essayer dans quelques instants."
            elif "api key" in error_str or "unauthorized" in error_str:
                return "Erreur d'authentification Groq. V√©rifiez votre cl√© API."
            else:
                return f"D√©sol√©, j'ai rencontr√© un probl√®me technique. Erreur: {str(e)}"
    
    def generate(self, prompt: str, system_prompt: str = None) -> str:
        """G√©n√®re une r√©ponse avec le meilleur provider disponible"""
        
        # Essayer Gemini en premier si disponible et dans les limites
        if self.should_use_gemini():
            try:
                self.current_provider = "gemini"
                return self.generate_with_gemini(prompt, system_prompt)
            except Exception as e:
                print(f"‚ö†Ô∏è √âchec Gemini: {e}")
        
        # Fallback vers Groq/Llama 3
        if self.groq_available:
            self.current_provider = "groq"
            return self.generate_with_groq(prompt, system_prompt)
        else:
            return "‚ùå Aucun LLM disponible. V√©rifiez votre configuration Gemini ou votre cl√© API Groq."
    
    def reset_gemini_availability(self):
        """R√©active Gemini (utile apr√®s une pause)"""
        if self.google_api_key:
            self.gemini_available = True
            print("üîÑ Gemini r√©activ√©")
    
    def get_status(self) -> Dict[str, Any]:
        """Retourne le statut du syst√®me"""
        return {
            "gemini_available": self.gemini_available,
            "groq_available": self.groq_available,
            "current_provider": self.current_provider,
            "token_usage": self.token_usage,
            "limits": {
                "hourly": self.token_limit_per_hour,
                "daily": self.token_limit_per_day
            },
            "usage_percentage": {
                "hourly": round((self.token_usage["hourly"]["tokens"] / self.token_limit_per_hour) * 100, 1),
                "daily": round((self.token_usage["daily"]["tokens"] / self.token_limit_per_day) * 100, 1)
            }
        }

# Instance globale
hybrid_llm_gemini = HybridLLMManagerGemini()