# api/cybersecurity_routes.py - VERSION CORRIG√âE
"""
Routes API pour l'agent de cybers√©curit√© avec int√©gration des mod√®les AI
"""
import logging
import sys
import os
from pathlib import Path
from fastapi import APIRouter, HTTPException, BackgroundTasks
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
import json
from datetime import datetime
import asyncio

# Ajouter le r√©pertoire racine au path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Configuration du logging
logger = logging.getLogger(__name__)

# IMPORTANT: Cr√©ation du router FastAPI
router = APIRouter()

# Import des mod√®les de s√©curit√© avec gestion d'erreur
try:
    from agents.cybersecurity_agent.custom_model_loaders import HuggingFaceSecurityModels
    security_models = HuggingFaceSecurityModels()
    MODELS_AVAILABLE = True
    logger.info("‚úÖ Mod√®les de s√©curit√© charg√©s avec succ√®s")
except Exception as e:
    logger.error(f"‚ùå Erreur chargement mod√®les de s√©curit√©: {e}")
    security_models = None
    MODELS_AVAILABLE = False

# Import de l'agent de cybers√©curit√©
try:
    from agents.cybersecurity_agent.enhanced_agent import EnhancedCybersecurityAgent
    cyber_agent = EnhancedCybersecurityAgent()
    AGENT_AVAILABLE = True
    logger.info("‚úÖ Agent de cybers√©curit√© charg√©")
except Exception as e:
    logger.error(f"‚ùå Erreur chargement agent cybers√©curit√©: {e}")
    cyber_agent = None
    AGENT_AVAILABLE = False

# Stockage des alertes et √©tat du syst√®me (partag√© avec server.py)
from api.shared_state import security_alerts, system_state

# Mod√®les Pydantic
class SecurityAnalysisRequest(BaseModel):
    text: str
    models: List[str] = ["vulnerability_classifier", "network_analyzer", "intent_classifier"]
    session_id: Optional[str] = "default"

class SecurityAnalysisResponse(BaseModel):
    vulnerability_classifier: Optional[Dict[str, Any]] = None
    network_analyzer: Optional[Dict[str, Any]] = None
    intent_classifier: Optional[Dict[str, Any]] = None
    overall_threat_level: str
    timestamp: str
    metadata: Dict[str, Any] = {}

class SecurityAlert(BaseModel):
    id: str
    type: str  # vulnerability, network, intent
    severity: str  # low, medium, high, critical
    message: str
    timestamp: str
    action_taken: str
    details: Optional[Dict[str, Any]] = {}

class SystemBlockRequest(BaseModel):
    reason: str
    severity: str = "critical"
    session_id: Optional[str] = None
    analysis: Optional[Dict[str, Any]] = None
    block_duration: Optional[int] = None  # en secondes

@router.get("/health")
async def security_health():
    """V√©rification de sant√© du syst√®me de s√©curit√©"""
    return {
        "status": "healthy" if MODELS_AVAILABLE else "degraded",
        "models_loaded": MODELS_AVAILABLE,
        "agent_available": AGENT_AVAILABLE,
        "system_state": system_state,
        "active_alerts": len(security_alerts),
        "version": "1.0.0"
    }

@router.post("/analyze")
async def analyze_security(request: SecurityAnalysisRequest):
    """Analyse de s√©curit√© d'un texte avec les mod√®les AI - VERSION CORRIG√âE"""
    try:
        logger.info(f"üîç Analyse de s√©curit√©: {request.text[:50]}...")
        
        results = {}
        threat_detected = False
        threat_score = 0.0
        
        # Si les mod√®les ne sont pas disponibles, utiliser une analyse basique
        if not MODELS_AVAILABLE or not security_models:
            logger.warning("‚ö†Ô∏è Mod√®les AI non disponibles, utilisation de l'analyse basique")
            
            # Analyse basique par mots-cl√©s
            text_lower = request.text.lower()
            
            # D√©tection de vuln√©rabilit√©s
            vuln_keywords = {
                "sql": ["select", "union", "drop table", "or 1=1", "' or '", "--", "';"],
                "xss": ["<script>", "alert(", "javascript:", "onerror=", "onload="],
                "injection": ["exec(", "eval(", "system(", "../", "..\\"]
            }
            
            for vuln_type, keywords in vuln_keywords.items():
                if any(keyword in text_lower for keyword in keywords):
                    results["vulnerability_classifier"] = {
                        "vulnerability_type": vuln_type.upper(),
                        "confidence": 0.85
                    }
                    threat_detected = True
                    threat_score += 0.85
                    break
            else:
                results["vulnerability_classifier"] = {
                    "vulnerability_type": "SAFE",
                    "confidence": 0.90
                }
            
            # D√©tection d'intentions malveillantes
            malicious_keywords = ["hack", "exploit", "vuln√©rabilit√©", "attaque", "ddos", "injection", "contourner"]
            if any(keyword in text_lower for keyword in malicious_keywords):
                results["intent_classifier"] = {
                    "intent": "Malicious",
                    "confidence": 0.80
                }
                threat_detected = True
                threat_score += 0.80
            else:
                results["intent_classifier"] = {
                    "intent": "Legitimate",
                    "confidence": 0.90
                }
            
        else:
            # Utiliser les mod√®les AI
            if "vulnerability_classifier" in request.models:
                try:
                    vuln_result = security_models.classify_vulnerability(request.text)
                    results["vulnerability_classifier"] = vuln_result
                    
                    if vuln_result.get("vulnerability_type") not in ["SAFE", "error"]:
                        threat_detected = True
                        threat_score += vuln_result.get("confidence", 0) * 1.5
                        
                        # Cr√©er une alerte
                        await create_alert(
                            type="vulnerability",
                            severity="high" if vuln_result.get("confidence", 0) > 0.8 else "medium",
                            message=f"Vuln√©rabilit√© d√©tect√©e: {vuln_result.get('vulnerability_type')}",
                            details=vuln_result
                        )
                except Exception as e:
                    logger.error(f"Erreur vulnerability_classifier: {e}")
                    results["vulnerability_classifier"] = {"error": str(e)}
            
            if "network_analyzer" in request.models:
                try:
                    net_result = security_models.analyze_network_traffic(request.text)
                    results["network_analyzer"] = net_result
                    
                    if net_result.get("traffic_type") not in ["NORMAL", "error"]:
                        threat_detected = True
                        severity = "critical" if net_result.get("traffic_type") == "DDOS" else "high"
                        threat_score += net_result.get("confidence", 0) * 2
                        
                        await create_alert(
                            type="network",
                            severity=severity,
                            message=f"Activit√© r√©seau suspecte: {net_result.get('traffic_type')}",
                            details=net_result
                        )
                except Exception as e:
                    logger.error(f"Erreur network_analyzer: {e}")
                    results["network_analyzer"] = {"error": str(e)}
            
            if "intent_classifier" in request.models:
                try:
                    intent_result = security_models.classify_intent(request.text)
                    results["intent_classifier"] = intent_result
                    
                    if intent_result.get("intent") == "Malicious":
                        threat_detected = True
                        threat_score += intent_result.get("confidence", 0) * 1.5
                        
                        await create_alert(
                            type="intent",
                            severity="high" if intent_result.get("confidence", 0) > 0.7 else "medium",
                            message=f"Intention malveillante d√©tect√©e (confiance: {intent_result.get('confidence', 0):.2%})",
                            details=intent_result
                        )
                except Exception as e:
                    logger.error(f"Erreur intent_classifier: {e}")
                    results["intent_classifier"] = {"error": str(e)}
        
        # Calculer le niveau de menace global
        if threat_score >= 2.5:
            threat_level = "critical"
        elif threat_score >= 1.5:
            threat_level = "high"
        elif threat_score >= 0.5:
            threat_level = "medium"
        elif threat_score > 0:
            threat_level = "low"
        else:
            threat_level = "safe"
        
        results["overall_threat_level"] = threat_level
        
        # Mettre √† jour l'√©tat du syst√®me
        system_state["threat_level"] = threat_level
        system_state["last_scan"] = datetime.now().isoformat()
        
        # Si menace critique, bloquer le syst√®me automatiquement
        if threat_level == "critical":
            logger.warning(f"üö® MENACE CRITIQUE D√âTECT√âE - Blocage automatique")
            await block_system(SystemBlockRequest(
                reason=f"Menace critique d√©tect√©e: {request.text[:50]}...",
                severity="critical",
                session_id=request.session_id,
                analysis=results
            ))
        
        # Ajouter les m√©tadonn√©es
        results["timestamp"] = datetime.now().isoformat()
        results["metadata"] = {
            "text_length": len(request.text),
            "models_used": request.models,
            "threat_detected": threat_detected,
            "threat_score": threat_score,
            "session_id": request.session_id
        }
        
        logger.info(f"‚úÖ Analyse termin√©e - Niveau de menace: {threat_level}")
        
        return SecurityAnalysisResponse(**results)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur analyse s√©curit√©: {e}")
        # Retourner une r√©ponse valide m√™me en cas d'erreur
        return SecurityAnalysisResponse(
            vulnerability_classifier={"error": str(e)},
            network_analyzer={"error": str(e)},
            intent_classifier={"error": str(e)},
            overall_threat_level="error",
            timestamp=datetime.now().isoformat(),
            metadata={"error": str(e)}
        )

@router.post("/alert")
async def create_alert(
    type: str,
    severity: str,
    message: str,
    details: Optional[Dict[str, Any]] = None
):
    """Cr√©er une alerte de s√©curit√©"""
    alert = SecurityAlert(
        id=f"alert_{datetime.now().timestamp()}",
        type=type,
        severity=severity,
        message=message,
        timestamp=datetime.now().isoformat(),
        action_taken="Alerte cr√©√©e et logg√©e",
        details=details or {}
    )
    
    security_alerts.append(alert.dict())
    
    # Limiter le nombre d'alertes stock√©es
    if len(security_alerts) > 100:
        security_alerts.pop(0)
    
    # Si alerte critique, notifier imm√©diatement
    if severity == "critical":
        logger.warning(f"üö® ALERTE CRITIQUE: {message}")
        system_state["active_threats"].append(alert.dict())
        system_state["total_threats_detected"] = system_state.get("total_threats_detected", 0) + 1
    
    logger.info(f"üö® Nouvelle alerte cr√©√©e: {type} - {severity} - {message}")
    
    return alert

@router.get("/alerts")
async def get_alerts(
    limit: int = 50,
    severity: Optional[str] = None,
    type: Optional[str] = None
):
    """R√©cup√©rer les alertes de s√©curit√©"""
    # Forcer l'utilisation de la liste partag√©e
    from api.shared_state import security_alerts as shared_alerts
    
    filtered_alerts = list(shared_alerts)  # Cr√©er une copie pour √©viter les modifications
    
    if severity:
        filtered_alerts = [a for a in filtered_alerts if a["severity"] == severity]
    
    if type:
        filtered_alerts = [a for a in filtered_alerts if a["type"] == type]
    
    # Trier par timestamp d√©croissant
    filtered_alerts.sort(key=lambda x: x["timestamp"], reverse=True)
    
    return {
        "alerts": filtered_alerts[:limit],
        "total": len(filtered_alerts),
        "filters": {
            "severity": severity,
            "type": type
        },
        "timestamp": datetime.now().isoformat()  # Pour forcer le refresh
    }

@router.post("/block")
async def block_system(request: SystemBlockRequest):
    """Bloquer le syst√®me pour des raisons de s√©curit√©"""
    system_state["blocked"] = True
    system_state["block_reason"] = request.reason
    system_state["block_time"] = datetime.now().isoformat()
    system_state["threat_level"] = "danger"
    
    # Cr√©er une alerte de blocage
    await create_alert(
        type="system",
        severity=request.severity,
        message=f"Syst√®me bloqu√©: {request.reason}",
        details={
            "duration": request.block_duration,
            "session_id": request.session_id,
            "analysis": request.analysis
        }
    )
    
    # Si dur√©e sp√©cifi√©e, d√©bloquer apr√®s le d√©lai
    if request.block_duration:
        asyncio.create_task(auto_unblock(request.block_duration))
    
    logger.warning(f"üö´ Syst√®me bloqu√©: {request.reason}")
    
    return {
        "status": "blocked",
        "reason": request.reason,
        "timestamp": system_state["block_time"]
    }

@router.post("/unblock")
async def unblock_system():
    """D√©bloquer le syst√®me"""
    system_state["blocked"] = False
    system_state["block_reason"] = None
    system_state["threat_level"] = "safe"
    system_state["active_threats"] = []
    
    logger.info("‚úÖ Syst√®me d√©bloqu√©")
    
    return {
        "status": "unblocked",
        "timestamp": datetime.now().isoformat()
    }

async def auto_unblock(duration: int):
    """D√©bloquer automatiquement le syst√®me apr√®s un d√©lai"""
    await asyncio.sleep(duration)
    if system_state["blocked"]:
        await unblock_system()
        logger.info(f"‚úÖ Syst√®me d√©bloqu√© automatiquement apr√®s {duration} secondes")

# Gestionnaire de mod√®les pour compatibilit√©
models_manager = security_models